{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non supervised learning\n",
    "\n",
    "## Autoencoders\n",
    "\n",
    "Suppose we have only a set of unlabeled training examples $x_1,x_2,x_3, \\dots $, where $x_i \\in \\Re^n$. \n",
    "\n",
    "An autoencoder neural network is an *unsupervised learning* algorithm that applies backpropagation and uses a loss function that is optimal when setting the target values to be equal to the inputs, $y_i=x_i$.\n",
    "\n",
    "To build an autoencoder, you need three things: an **encoding function**, a **decoding function**, and a **distance function** between the amount of information loss between the compressed representation of your data and the decompressed representation.\n",
    "\n",
    "<center>\n",
    "<img src=\"https://blog.keras.io/img/ae/autoencoder_schema.jpg\" alt=\"\" style=\"width: 700px;\"/>\n",
    "</center>\n",
    "\n",
    "Two practical applications of autoencoders are data denoising, and dimensionality reduction for data visualization. In addition, it has shown to be an improvement over Matrix Factorization algorithms for Recommender Systems. \n",
    "\n",
    "With appropriate dimensionality and sparsity constraints, autoencoders can learn data projections that are more interesting than PCA or other basic techniques.\n",
    "\n",
    "We'll start simple, with a single fully-connected neural layer as encoder and as decoder:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's prepare our input data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "(x_train, _), (x_test, _) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a simple 1-hidden layer AE\n",
    "\n",
    "Remember the steps:\n",
    "\n",
    " - build the model\n",
    " - compile\n",
    " - fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Autoencoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Predict some images\n",
    "\n",
    "Note that here `predict` does not mean to predict a label, but rather a forward pass through the network (i.e. inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoded_imgs = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(10, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note that we can also create a separate encoder model and a separate decoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this model maps an input to its encoded representation\n",
    "encoding_model = ...\n",
    "\n",
    "# create a placeholder for an encoded input\n",
    "# and create the decoder model\n",
    "decoding_model = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# encode and decode some digits\n",
    "# note that we take them from the *test* set\n",
    "encoded_imgs = ...\n",
    "decoded_imgs = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Plot results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try doing the same with larger hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding a sparsity constraint on the encoded representations\n",
    "\n",
    "In the previous example, the representations were only constrained by the size of the hidden layer (32). In such a situation, what typically happens is that the hidden layer is learning an approximation of PCA (principal component analysis). But another way to constrain the representations to be compact is to add a sparsity contraint on the activity of the hidden representations, so fewer units would \"fire\" at a given time. \n",
    "\n",
    "In Keras, this can be done by adding an ``activity_regularizer`` to our Dense layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import regularizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Autoencoder with L1 activity regularizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Going deep\n",
    "\n",
    "Compare the loss with the shallow case. Does it get any better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Try 784-128-64-32-64-128-784 architecture with relu activations and sigmoid in the last layer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Image denoising\n",
    "\n",
    "It's simple: we will train the autoencoder to map noisy digits images to clean digits images.\n",
    "\n",
    "Here's how we will generate synthetic noisy digits: we just apply a gaussian noise matrix and clip the images between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "(x_train, _), (x_test, _) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = np.reshape(x_train, (len(x_train), 784))\n",
    "x_test = np.reshape(x_test, (len(x_test), 784))\n",
    "\n",
    "noise_factor = 0.5\n",
    "x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape) \n",
    "x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape) \n",
    "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
    "x_test_noisy = np.clip(x_test_noisy, 0., 1.)\n",
    "\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 2))\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(1, n, i+1)\n",
    "    plt.imshow(x_test_noisy[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#display original, noisy and reconstruction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational Autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display_html\n",
    "def restartkernel():\n",
    "    display_html(\"<script>Jupyter.notebook.kernel.restart()</script>\",raw=True)\n",
    "restartkernel()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Lambda\n",
    "from keras.models import Model\n",
    "from keras.objectives import binary_crossentropy, mse\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "A variational autoencoder is an autoencoder that adds probabilistic constraints on the representations being learned. \n",
    "\n",
    "> When using probabilistic models, **compressed representation** is called **latent variable model**. \n",
    "\n",
    "So, instead of learning a function this model is learning a probabilistic distribution function that models your data.\n",
    "\n",
    "> Why? Standard autoencoders are not suited to work as a generative model. If you pick a random value for your decoder you won't get necessarily a good reconstruction: the value can far away from any previous value the network has seen before! That's why attaching a probabilistic model to the compressed representation is a good idea! \n",
    "\n",
    "For sake of simplicity, let's use a standard normal distribution to define the distribution of inputs ($\\mathbf V$) the decoder will receive. \n",
    "\n",
    "The architecture of a variational autoencoder (VAE) is thus:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"http://ijdykeman.github.io/assets/cvae_figures/ae_diagram.svg\" alt=\"\" style=\"width: 300px;\"/> \n",
    "(Source: http://ijdykeman.github.io/ml/2016/12/21/cvae.html)\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want the decoder to take any point taken from a standard normal distribution to return a reasonable element of our dataset:\n",
    "\n",
    "<center>\n",
    "<img src=\"http://ijdykeman.github.io/assets/cvae_figures/vae_decoder_diagram.svg\" alt=\"\" style=\"width: 500px;\"/> \n",
    "(Source: http://ijdykeman.github.io/ml/2016/12/21/cvae.html)\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider the encoder role in this architecture. \n",
    "\n",
    "In a traditional autoencoder, the encoder model takes a sample from data and returns a single point in the latent space, which is then passed to the decoder.\n",
    "\n",
    "> What information is encoded in the latent space?\n",
    "\n",
    "In VAE the encoder instead produces (the parameters of) a probability distribution in the latent space:\n",
    "\n",
    "<center>\n",
    "<img src=\"http://ijdykeman.github.io/assets/cvae_figures/encoder_vae_diagram.svg\" alt=\"\" style=\"width: 500px;\"/> \n",
    "(Source: http://ijdykeman.github.io/ml/2016/12/21/cvae.html)\n",
    "</center>\n",
    "\n",
    "These distributions are (non standard) Gaussians of the same dimensionality as the latent space. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let’s implement the encoder net, which takes input $X$ and outputs two things: $\\mu(X)$ and $\\Sigma(X)$, the parameters of the Gaussian. Our encoder will be a neural net with one hidden layer. \n",
    "\n",
    "Our latent variable is two dimensional, so that we could easily visualize it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data with labels for visualization purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MNIST dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# network parameters\n",
    "input_shape = (original_dim, )\n",
    "intermediate_dim = 512\n",
    "batch_size = 100\n",
    "latent_dim = 2\n",
    "epochs = 25\n",
    "epsilon_std=0.05 # This parameter is the most critical one, as it determines the sampling"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Create a decoder architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up to now we have an encoder that takes images and produce (the parameters of) a pdf in the latent space.  The decoder takes points in the latent space and return reconstructions.\n",
    "\n",
    "How do we connect both models? By sampling from the produced distribution!\n",
    "\n",
    "\n",
    "<center>\n",
    "<img src=\"http://ijdykeman.github.io/assets/cvae_figures/vae_diagram.svg\" alt=\"\" style=\"width: 400px;\"/> \n",
    "(Source: http://ijdykeman.github.io/ml/2016/12/21/cvae.html)\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To this end we will implement a *random variate reparameterisation*: the substitution of a random variable by a deterministic transformation of a simpler random variable.\n",
    "\n",
    "There are several methods by which non-uniform random numbers, or random variates, can be generated. The most popular methods are the **one-liners**, which give us the simple tools to generate random variates in one line of code, following the classic paper by Luc Devroye (Luc Devroye, Random variate generation in one line of code, Proceedings of the 28th conference on Winter simulation, 1996).\n",
    "\n",
    "In the case of a Gaussian, we can use the following algorithm:\n",
    "+ Generate $\\epsilon \\sim \\mathcal{N}(0;1)$.\n",
    "+ Compute a sample from $\\mathcal{N}(\\mu; RR^T)$ as $\\mu + R \\epsilon$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Implement the above formula\n",
    "\n",
    "def sampling(args):\n",
    "    return \n",
    "\n",
    "# note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "# so you could write `Lambda(sampling)([z_mean, z_log_sigma])`\n",
    "z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_sigma])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create the decoder net:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, from this model, we can do three things: reconstruct inputs, encode inputs into latent variables, and generate data from latent variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to be coherent with our previous definitions, we must assure that points sampled fron the latent space fit a standard normal distribition, but the encoder is producing non standard normal distributions. So, we must add a constraint for getting something like this:\n",
    "\n",
    "<center>\n",
    "<img src=\"http://ijdykeman.github.io/assets/cvae_figures/kl_divergence_diagram.svg\" alt=\"\" style=\"width: 700px;\"/> \n",
    "(Source: http://ijdykeman.github.io/ml/2016/12/21/cvae.html)\n",
    "</center>\n",
    "\n",
    "In order to impose this constraint in the loss function by using the Kullback-Leibler divergence.\n",
    "\n",
    "> The Kullback–Leibler divergence is a measure of how one probability distribution diverges from a second expected probability distribution. \n",
    "For discrete probability distributions $P$ and $Q$, the Kullback–Leibler divergence from $Q$ to $P$ is defined to be\n",
    "$$ D_{\\mathrm {KL} }(P\\|Q)=\\sum _{i}P(i)\\,\\log {\\frac {P(i)}{Q(i)}}. $$\n",
    "\n",
    "The rest of the loss function must take into account the \"reconstruction\" error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.losses import mse, binary_crossentropy\n",
    "def vae_loss(y_true, y_pred):\n",
    "    \"\"\" \n",
    "    Calculate loss = reconstruction loss + \n",
    "    KL loss for each data in minibatch \n",
    "    \"\"\"\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a VAE\n",
    "\n",
    "How do we train a model that have a sampling step? \n",
    "\n",
    "<center>\n",
    "<img src=\"images/vae_sampling.png\" alt=\"\" style=\"width: 800px;\"/> \n",
    "</center>\n",
    "\n",
    "In fact this is not a problem! By using the *one-linear* method for sampling we have expressed the latent distribution in a way that its parameters are factored out of the parameters of the random variable so that backpropagation can be used to find the optimal parameters of the latent distribution. For this reason this method is called *reparametrization trick*.\n",
    "\n",
    "By using this trick we can train end-to-end a VAE with backpropagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excercises\n",
    "\n",
    "* Play with the smapling parameter epsilon_std\n",
    "* Create a VAE model with several layers (deep AE)\n",
    "* Change the reconstruction loss to mse or mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deeper network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display_html\n",
    "def restartkernel():\n",
    "    display_html(\"<script>Jupyter.notebook.kernel.restart()</script>\",raw=True)\n",
    "restartkernel()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Lambda\n",
    "from keras.models import Model\n",
    "from keras.objectives import binary_crossentropy\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MNIST dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# network parameters\n",
    "input_shape = (original_dim, )\n",
    "intermediate_dim = [512, 128, 32]\n",
    "batch_size = 100\n",
    "latent_dim = 2\n",
    "epochs = 30\n",
    "epsilon_std = 1e-3 # This parameter is the most critical one, as it determines the sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# VAE model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mse error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display_html\n",
    "def restartkernel():\n",
    "    display_html(\"<script>Jupyter.notebook.kernel.restart()</script>\",raw=True)\n",
    "restartkernel()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Lambda\n",
    "from keras.models import Model\n",
    "from keras.objectives import binary_crossentropy, mse\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MNIST dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# network parameters\n",
    "input_shape = (original_dim, )\n",
    "intermediate_dim = 512\n",
    "batch_size = 100\n",
    "latent_dim = 2\n",
    "epochs = 25\n",
    "epsilon_std = 5e-4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# VAE model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Plot results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dl_win]",
   "language": "python",
   "name": "conda-env-dl_win-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
